---
title: "Training Peaks"
# output:
#   html_notebook:
#     toc: true
#     toc_depth: 3
#     toc_float:
#       collapsed: false
#       smooth_scroll: true
#     theme: cosmo
#     df_print: paged
#     highlight: tango
#     # code_folding: hide
#     # fig_width: 12
#     # fig_height: 12
output:
  epuRate::BAKER:
    toc: TRUE
    number_sections: FALSE
    code_folding: "show"
---

<script>
$(document).ready(function() {
  $items = $('div#TOC li');
  $items.each(function(idx) {
    num_ul = $(this).parentsUntil('#TOC').length;
    $(this).css({'text-indent': num_ul * 10, 'padding-left': 0});
  });

});
</script>

***

# TrainingPeaks Data

## Preliminary tasks
### Load Libraries

Load libraries for reading fit data and create maps and plots.

```{r warning=FALSE, results='hide', echo='FALSE'}
library(fit)
library(ggplot2)
library(dplyr)
library(stringr)
library(foreach)
library(doParallel)
library(zoo)
library(splines)
```

*** 

# Activity per athlete

> **Note**
>
> We are missing personal data from all patients (Name, VO2max, Weight, etc.)

## Initial set-up

### Load src files

```{r}
source('src/ctt_definition.R') # constant variables and files
source('src/f_getactivityinfo.R') # main functions to get info from activity
source('src/f_getpowspeedzones.R') # functions to get power/speed zones for new trimp scores
```

### Select athletes and directory

```{r}
sel.athletes <- c("LOICSEGAERT","RUBENAPERS","SANDERDEPESTEL","ARNEMARIT","AARONVANPOUCKE",
                  "FERGUSSULLY","MATHEWROSS", "CYRUSMONK","BENTLEYOLDEN",
                  "DAVIDRANDALL","WARDVANHOOF","ROBSCHEERLINCK","TRISTANGERRYN")
# sel.athletes <- c("RUBENAPERS","BENTLEYOLDEN")
# sel.athletes <- c("RUBENAPERS")
sel.athletes <- c("LOICSEGAERT")

# all folders in PRO_HEART
all.dirs.PH <- list.dirs(list.dirs('PRO_HEART',recursive = F),recursive=F)
```

### Load previous results

```{r}
if(file.exists('rdas/tpeaks_newzones.rda')){
  load('rdas/tpeaks_newzones.rda')
}
```

### Load test maxHR data

```{r}
if (file.exists('athlete_maxHR.txt')){
  lab.maxHR <- read.table('athlete_maxHR.txt')
  colnames(lab.maxHR) <- c('name','maxHR')
}
```


***

## Step 1

First of all, we will check if the athlete has already been processed

* MaxHR has been calculated from all the activities
* Power/Speed zones have been determined

```{r}
# rm(tp.newzones)
 writeLines(c("###############################",
               "##   TRAININGPEAKS PROJECT   ##",
               "###############################"))
for (athlete in sel.athletes){
  writeLines(c("","###############################",
               "Calculating maxHR and HR/Power/Speed correlations...",
               paste0("Working with athlete ",athlete),""))
  
  # check if we already have the info
  if(!exists("tp.newzones")){
    writeLines(c("Nothing loaded or previously computed...",
                 "Running everything for the first time."))
    tp.newzones <- data.frame(name=athlete, ath.id=paste0("BA_",str_pad(1,3,pad="0")),
                              maxHR= NA, stringsAsFactors=FALSE)
  } else {
    # if there is no row for the athlete, create one
    if(!athlete %in% tp.newzones$name){
      writeLines(c("Unknown athlete, creating a new entry."))
      tp.newzones[nrow(tp.newzones)+1,'name'] <- athlete
      tp.newzones$ath.id[tp.newzones$name == athlete] <- paste0("BA_",str_pad(dim(tp.newzones)[1],3,pad="0"))
    } else if (!is.na(tp.newzones$maxHR[tp.newzones$name == athlete])) {
      # if there already is a row with a not NA maxHR, the athlete has already been processed --> skip
      # if(dim(tp.newzones[tp.newzones$name == athlete,])[1] != 0
      #    && !is.na(tp.newzones$maxHR[tp.newzones$name == athlete])){
      writeLines(paste0("Zones already calculated, skipping athlete ",athlete))
      next
    }
  }
  # you should be here if the athlete has not been processed, with a new row in the table
  # we need to check now if there is a lab-measured maxHR
  # if not, we will use 180 as default (to smooth HR over that later)
  if (exists('lab.maxHR')){
    ath.maxHR <- if (athlete %in% lab.maxHR$name) {lab.maxHR$maxHR[lab.maxHR$name == athlete]} else {180}
  } else {
    ath.maxHR <- 180
  }
  # Finally, run the function to get the zones and update the tp.newzones table
  tp.newzones <- update.ath_info_with_newzones(tp.newzones, athlete, ath.maxHR)
}
# save everything in a file, so we don't need to calculate them every time
save(tp.newzones,file='rdas/tpeaks_newzones.rda')
tp.newzones
```

***

## Step 2

Now we have all athletes with the maxHR determined in the lab or by the activity data (the highest) and the power/speed zones calculated and saved in a file.

Next step is to get all the files and compute all what we need.

There are different checks to be sure that the activity is processed and saved correctly:

* The file is a fit file and is readable by the fit package
* The activity contains data and is longer than 1 min
* There are no errors processing the file (year in the future, time jumps, etc)

### Read files for each of the athlete

```{r}
tpeaks.all <- NULL
for (athlete in sel.athletes){
  writeLines(c("","###############################",
               "Processing all fit files...",
               paste0("Working with athlete ",athlete),""))
  
  sel.dirs <- list.dirs(all.dirs.PH[str_detect(all.dirs.PH,athlete)],recursive=F)
  sel.dirs <- sel.dirs[str_detect(sel.dirs,"YEAR")]
  files <- list.files(sel.dirs,pattern=".fit",full.names = TRUE)
  ath.id <- tp.newzones$ath.id[tp.newzones$name == athlete]
  ath.maxHR <- tp.newzones$maxHR[tp.newzones$name == athlete]
  
  ###################
  # initialize cluster
  ###################
  # set up number of cores
  cores <- detectCores()
  cl <- makeCluster(cores[1]-1) #not to overload your computer
  registerDoParallel(cl)
  start <- Sys.time()

  tp.athlete <- NULL
  tp.athlete <- foreach (file=files, .combine=rbind,
                         # .export=c("get.act_info_from_fitdata","smooth.data","onerow.df","get.date_GARMIN"),
                         .packages=c("dplyr", "fit", "stringr", "zoo", "splines")) %dopar% {
    temp.tp.athlete <- process.fitfile(file, ath.id)
    temp.tp.athlete
  }
  end <- Sys.time()
  duration <- end-start
  print(duration)
  stopCluster(cl)
  tpeaks.all <- rbind(tpeaks.all,tp.athlete)
  rownames(tpeaks.all) <- NULL
}
# save everything in a file, so we don't need to calculate them every time
save(tpeaks.all,file=paste0('rdas/tpeaks_all_',format(as.Date(Sys.Date()),format="%y%m%d"),'.rda'))
# tpeaks.all
```

***

## Step 3

### SUMMARIZE STUFF

split training.all into correct sessions, duplicate and error

```{r}
# levels(training.all$file) <- c(levels(training.all$file),"PRO_HEART/AUS_PH/BENTLEYOLDEN/FULL_2YEARS/kk.fit","PRO_HEART/AUS_PH/BENTLEYOLDEN/MONTH_2YEARS/2018-09-28-203213-ELEMNT 3AE9-91-0.fit")
# training.all[8,]$file <- "PRO_HEART/AUS_PH/BENTLEYOLDEN/FULL_2YEARS/kk.fit"
# training.all[7,]$file <- "PRO_HEART/AUS_PH/BENTLEYOLDEN/MONTH_2YEARS/2018-09-28-203213-ELEMNT 3AE9-91-0.fit"
error.sessions <- tpeaks.all %>% filter(str_detect(date,"error")) %>% select(file,reason=date)
# check if file has already been processed in a different folder (some cases with full/monthly divisions)
dup.sessions <- tpeaks.all %>%
  filter(!str_detect(date,"error")) %>% 
  mutate(filename=sapply(str_split(file,"/"),function(x) x[5])) %>%
  group_by(ath.id,filename) %>%
  mutate(id=row_number(),source=first(file)) %>%
  ungroup() %>%
  mutate_if(is.factor, as.character) %>%
  filter(id >1) %>%
  mutate(reason="duplicated file") %>%
  select(ath.id,file,source,reason)
# update all.activities
all.activities <- tpeaks.all %>%
  filter(!str_detect(date,"error")) %>% 
  mutate(filename=sapply(str_split(file,"/"),function(x) x[5])) %>%
  group_by(ath.id,filename) %>%
  mutate(id=row_number(),source=first(file)) %>%
  ungroup() %>%
  mutate_if(is.factor, as.character) %>%
  filter(id == 1) %>% 
  select(-filename,-source,-id)
# get duplicated activities based on time, etc
dup.sessions <- rbind(dup.sessions,all.activities %>%
  group_by(ath.id,date,start_time,duration.min) %>%
  mutate(id=row_number(),source=first(file)) %>%
  ungroup() %>%
  mutate_if(is.factor, as.character) %>%
  filter(id > 1) %>%
  mutate(reason="repeated activity") %>%
  select(ath.id,file,source,reason))
# unique activities
all.activities <- all.activities %>%
  group_by(ath.id,date,start_time,duration.min) %>%
  mutate(id=row_number(),source=first(file)) %>%
  ungroup() %>%
  mutate_if(is.factor, as.character) %>%
  filter(id == 1) %>% 
  select(-source,-id)
```

populate ath.info

```{r}
cohort_vs_athlete <- as.data.frame(t(do.call("cbind",str_split(str_remove(all.dirs.PH,"PRO_HEART/"),"/"))))
ath.info <- merge(merge(tp.newzones, cohort_vs_athlete,by.x="name",by.y="V2") %>% select(name,ath.id,cohort=V1),
                  all.activities %>%
                    mutate(folder=tolower(sapply(str_split(file,"/"),function(x) x[4]))) %>%
                    group_by(ath.id) %>%
                    summarise(total_activities=n(), 
                              month_2_year_0=sum(folder=="month_2_year_0"),
                              month_12_year_0=sum(folder=="month_12_year_0"),
                              month_2_year_2=sum(folder=="month_2_year_2"),
                              month_12_year_2=sum(folder=="month_12_year_2"),
                              full_2years=sum(folder=="full_2years"),
                              n_cycling=sum(sport_type=="Cycling"),
                              n_running=sum(sport_type=="Running"),
                              n_other=sum(!grepl("Running|Cycling",sport_type)),
                              n_heart=sum(!is.na(hr.avg)),n_power=sum(!is.na(power.avg)),
                              n_heart_power=sum(!is.na(power.avg) & !is.na(hrmax.activity))), by='ath.id', all=T) %>%
  mutate(perc_heart=round(n_heart/total_activities*100,2),perc_power = round(n_power/total_activities*100,2), perc_heart_power = round(n_heart_power/total_activities*100,2)) %>% 
  arrange(cohort,ath.id)
# add error and duplicate count
for (i in ath.info$name) {
  ath.info[ath.info$name==i,'n_error'] <- sum(!is.na(str_extract(error.sessions$file,i)))
  ath.info[ath.info$name==i,'n_duplicates'] <- sum(!is.na(str_extract(dup.sessions$file,i)))
}
# add year count
year.info <- all.activities %>% group_by(ath.id,year) %>% tally() %>% mutate(n=as.numeric(n))
for (i in ath.info$ath.id) {
  for (year in unique(year.info$year)){
    year_n <- as.numeric(year.info[as.character(year.info$ath.id) == i & year.info$year == year,"n"])
    ath.info[ath.info$ath.id==i,paste0("n_",year)] <- if(is.na(year_n)){0}else{year_n}
  }
}

ath.info
```


```{r}
save(ath.info,tpeaks.all,all.activities,error.sessions,dup.sessions,file=
       paste0("rdas/trainingpeaks_results_",format(as.Date(Sys.Date()),format="%y%m%d"),".rda"))
```



* Number of Activities
* Volume (Time)
* Intensity
  * %HRmax
  * Thresholds (Time in T1/T2)
  * Volume x %HRmax
* Sessions per week
* Average time
* Average speed (cycling vs running, etc?)
  * Event type = 1 == cycling??
  * sport = 2?
    * 2 = cycling
    * 5 = swimming
  * https://developer.garmin.com/downloads/connect-iq/monkey-c/doc/Toybox/ActivityRecording.html
* Average HR
* Heart beats per week/year of training
* Average accumulated power
* Data from TrainingPeaks? (data$session)
  * Calories
  * Total ascent
  * max_power
  * average_power / normalized_power
  * total work
  * training_stress_score
  * total_distance
  * intensity_factor
  * avg_HR

  * Average accumulated power (ATHLETE CALCULATION)
* Heart beats per week/year of training (ATHLETE CALCULATION)
* Data from TrainingPeaks? (data$session)
  * Calories

  * Thresholds (Time in Z5/Z4/Z3)
https://blogs.sas.com/content/efs/2018/01/26/data-driven-fitness-vo2-max-lactate-threshold-heart-rate/


Summarize power and add to ath.info

```{r}
# load('trainingpeaks_data_PARALLEL_200701.rda')
# 
write.csv(tp.newzones,file=paste0("csv/tpeaks_summary_newzones_",format(as.Date(Sys.Date()),format="%y%m%d"),".csv"))
write.csv(ath.info, file=paste0("csv/tpeaks_summary_athletes_",format(as.Date(Sys.Date()),format="%y%m%d"),".csv"))
write.csv(all.activities, file=paste0("csv/tpeaks_summary_activities_",format(as.Date(Sys.Date()),format="%y%m%d"),".csv"))
write.csv(error.sessions, file=paste0("csv/tpeaks_summary_error_",format(as.Date(Sys.Date()),format="%y%m%d"),".csv"))
write.csv(dup.sessions, file=paste0("csv/tpeaks_summary_dups_",format(as.Date(Sys.Date()),format="%y%m%d"),".csv"))
```
