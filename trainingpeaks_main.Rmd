---
title: "Training Peaks"
# output:
#   html_notebook:
#     toc: true
#     toc_depth: 3
#     toc_float:
#       collapsed: false
#       smooth_scroll: true
#     theme: cosmo
#     df_print: paged
#     highlight: tango
#     # code_folding: hide
#     # fig_width: 12
#     # fig_height: 12
output:
  epuRate::BAKER:
    toc: TRUE
    number_sections: FALSE
    code_folding: "show"
---

<script>
$(document).ready(function() {
  $items = $('div#TOC li');
  $items.each(function(idx) {
    num_ul = $(this).parentsUntil('#TOC').length;
    $(this).css({'text-indent': num_ul * 10, 'padding-left': 0});
  });

});
</script>

***

# TrainingPeaks Data

## Preliminary tasks
### Load Libraries

Load libraries for reading fit data and create maps and plots.

```{r warning=FALSE, results='hide', echo='FALSE'}
library(fit)
library(ggplot2)
library(dplyr)
library(stringr)
library(foreach)
library(doParallel)
library(zoo)
library(splines)
library(openxlsx)
library(geosphere)
library(XML)
library(tidyr)
library(readr)
```

*** 

# Activity per athlete

> **Note**
>
> We are missing personal data from all patients (Name, VO2max, Weight, etc.)

## Initial set-up

### Load src files

```{r}
source('src/ctt_definition.R') # constant variables and files
source('src/f_getactivityinfo.R') # main functions to get info from activity
source('src/f_getpowspeedzones.R') # functions to get power/speed zones for new trimp scores
source('src/f_getgpxactivity.R') # functions for reading gpx files
source('src/f_getmaxhrtangent.R') # functions to get maxHR with tangent method
source('src/f_gettcxactivity.R') # functions for reading tcx files
```

### Select athletes and directory

```{r}
# DECLARE NAME OF ATHLETES TO ANALYZE
# sel.athletes <- c("NAME")
lab.maxHR <- read.table("data/athlete_maxHR.txt",stringsAsFactors = F)
colnames(lab.maxHR) <- c('name','maxHR')
sel.athletes <- lab.maxHR$name

# all folders in PRO_HEART, where sel.athletes folders are located
ph_folders1 <- list.dirs('../ATHLETES/',recursive = F)
# ph_folders2 <- list.dirs(list.dirs('../../2003_TRAININGPEAKS/PRO_HEART',recursive = F),recursive=F)
# ph_folders3 <- list.dirs('../../2101_TRAININGPEAKS/MASTER_HEART',recursive = F)
# ph_folders4 <- list.dirs(list.dirs('../../2107_TRAININGPEAKS', recursive=F), recursive = F)
# ph_folders5 <- list.dirs(list.dirs('../../2201_UPDATE', recursive=F), recursive = F)
all.dirs.PH <- c(ph_folders1)
```

### Load test maxHR data, lab goldVT values and test dates

***

## Step 1

First of all, we will check if the athlete has already been processed

* MaxHR has been calculated from all the activities
* Power/Speed zones have been determined

```{r}
# rm(tp.newzones)
###################
# initialize cluster
###################
# set up number of cores
# cores <- detectCores()
# cl <- makeCluster(cores[1]-1) #not to overload your computer
# registerDoParallel(cl)

writeLines(c("###############################",
             "##   TRAININGPEAKS PROJECT   ##",
             "###############################"))
for (athlete in sel.athletes){
  writeLines(c("","###############################",
               "Calculating maxHR and HR/Power/Speed correlations...",
               paste0("Working with athlete ",athlete),""))
  
  # check if we already have the info
  if(!exists("tp.newzones")){
    writeLines(c("Nothing loaded or previously computed...",
                 "Running everything for the first time."))
    tp.newzones <- data.frame(name=athlete, ath.id=paste0("KJ_",str_pad(1,3,pad="0")),
                              maxHR= NA, stringsAsFactors=FALSE)
  } else {
    # if there is no row for the athlete, create one
    if(!athlete %in% tp.newzones$name){
      writeLines(c("Unknown athlete, creating a new entry."))
      tp.newzones[nrow(tp.newzones)+1,'name'] <- athlete
      tp.newzones$ath.id[tp.newzones$name == athlete] <- paste0("KJ_",str_pad(dim(tp.newzones)[1],3,pad="0"))
    } else if (!is.na(tp.newzones$maxHR[tp.newzones$name == athlete])) {
      # if there already is a row with a not NA maxHR, the athlete has already been processed --> skip
      # if(dim(tp.newzones[tp.newzones$name == athlete,])[1] != 0
      #    && !is.na(tp.newzones$maxHR[tp.newzones$name == athlete])){
      writeLines(paste0("Zones already calculated, skipping athlete ",athlete))
      next
    }
  }
  ### SRC COMMENT NEXT SECTION AS TANGENT METHOD DOESNT NEED LAB MAXHR
  ### SET IT TO 190 TO HAVE A MINIMUM TO SMOOTH TO REMOVE SPIKES
  # you should be here if the athlete has not been processed, with a new row in the table
  # we need to check now if there is a lab-measured maxHR
  # if not, we will use 180 as default (to smooth HR over that later)
  if (exists('lab.maxHR')){
    if (athlete %in% lab.maxHR$name) {
      ath.maxHR <- lab.maxHR$maxHR[lab.maxHR$name == athlete]
      tp.newzones[tp.newzones$name == athlete,"lab.maxHR"] <- ath.maxHR
    } else {
        ath.maxHR <- 999
        tp.newzones[tp.newzones$name == athlete,"lab.maxHR"] <- NA
    }
  } else {
    ath.maxHR <- 999
    tp.newzones[tp.newzones$name == athlete,"lab.maxHR"] <- NA
  }
  tp.newzones[tp.newzones$name == athlete,"maxHR"] <- ath.maxHR
  # Finally, run the function to get the zones and update the tp.newzones table
  # also, add the new "goldVT" zones, to include in the calculation later
  # save(tp.newzones,file='out/rdas/tpeaks_newzones.rda')
}
# stop cluster
# stopCluster(cl)
# save everything in a file, so we don't need to calculate them every time
# save(tp.newzones,file='out/rdas/tpeaks_newzones.rda')
tp.newzones
```

***

## Step 2

Now we have all athletes with the maxHR determined in the lab or by the activity data (the highest) and the power/speed zones calculated and saved in a file.

Next step is to get all the files and compute all what we need.

There are different checks to be sure that the activity is processed and saved correctly:

* The file is a fit file and is readable by the fit package
* The activity contains data and is longer than 1 min
* There are no errors processing the file (year in the future, time jumps, etc)

### Read files for each of the athlete

```{r}
tpeaks.all <- NULL
###################
# initialize cluster
###################
# set up number of cores
cores <- detectCores()
cl <- makeCluster(cores[1]-1) #not to overload your computer
registerDoParallel(cl)

for (athlete in sel.athletes){
  writeLines(c("","###############################",
               "Processing all fit files...",
               paste0("Working with athlete ",athlete),""))
  
  # edit 211020, check all folders, not just the first one!
  sel.dirs.tmp <- all.dirs.PH[str_detect(all.dirs.PH, athlete)]
  files <- list.files(sel.dirs.tmp, pattern="*.*", recursive=T, full.names=T)
  files <- files[!str_detect(files, ".zip$")]
  ath.id <- tp.newzones$ath.id[tp.newzones$name == athlete]
  ath.maxHR <- tp.newzones$maxHR[tp.newzones$name == athlete]
  
  start <- Sys.time()
  tp.athlete <- NULL
  tp.athlete <- foreach (file=files, .combine=rbind,
                         # .export=c("get.act_info_from_fitdata","smooth.data","onerow.df","get.date_GARMIN"),
                         .packages=c("dplyr", "fit", "stringr", "zoo", "splines","geosphere","XML","tidyr", "xml2")) %dopar% {
    temp.tp.athlete <- process.fitfile(file, ath.id)
    temp.tp.athlete
  }
  end <- Sys.time()
  duration <- end-start
  print(duration)
  tpeaks.all <- rbind(tpeaks.all,tp.athlete)
  rownames(tpeaks.all) <- NULL
}
# stop cluster
stopCluster(cl)

# save everything in a file, so we don't need to calculate them every time
# save(tpeaks.all,file=paste0('out/rdas/tpeaks_all_',format(as.Date(Sys.Date()),format="%y%m%d"),'.rda'))
# tpeaks.all
```

```{r}
# load('trainingpeaks_data_PARALLEL_200701.rda')
# 
# save CSV
# write.csv(tp.newzones,file=paste0("out/csv/tpeaks_summary_newzones_",format(as.Date(Sys.Date()),format="%y%m%d"),".csv"))
# write.csv(ath.info.test, file=paste0("out/csv/tpeaks_summary_athletes_",format(as.Date(Sys.Date()),format="%y%m%d"),".csv"))
# write.csv(all.activities, file=paste0("out/csv/tpeaks_summary_activities_",format(as.Date(Sys.Date()),format="%y%m%d"),".csv"))
# write.csv(error.sessions, file=paste0("out/csv/tpeaks_summary_error_",format(as.Date(Sys.Date()),format="%y%m%d"),".csv"))
# write.csv(dup.sessions, file=paste0("out/csv/tpeaks_summary_dups_",format(as.Date(Sys.Date()),format="%y%m%d"),".csv"))
# save all in an XLSX file
sheet_list <- list("athletes"= tp.newzones,
                   "activities"= tpeaks.all)
write.xlsx(sheet_list, keepNA=TRUE,
           file=paste0("out/trainingpeaks_results_",format(as.Date(Sys.Date()),format="%y%m%d"),".xlsx"))
```
